---
title: "Homework 1"
subtitle: "Research Methods, Spring 2026"
author: "Answer Key"
format:
  pdf:
    output-file: "mccarthy-i-hwk1-1py"
    output-ext:  "pdf"
    header-includes:
      - \usepackage{float}
      - \floatplacement{table}{H}
---

```{python}
#| include: false

from pathlib import Path
import numpy as np
import pandas as pd

pd.set_option("display.max_columns", 200)
pd.set_option("display.width", 140)
```

My answers to the homework questions are described below. Note that code and data are available [here](https://github.com/imccart/homework1.git). Enjoy!

```{python}
#| include: false

plan_data = pd.read_csv("data/output/plan_data.csv", encoding="latin1")
service_data = pd.read_csv("data/output/service_area.csv", encoding="latin1")

def _not_na_string(s):
    return s.notna() & (s.astype(str) != "NA")

# 1) All plan types (as in the R answer key)
plan_type_year1 = (
    plan_data.loc[_not_na_string(plan_data["plan_type"])]
    .groupby("plan_type", dropna=False)
    .size()
    .reset_index(name="Count")
    .sort_values("Count", ascending=False)
)

# 2) Excluding SNP, EGHP, and 800-series plans
# (Keep the same filter logic: snp == "No", eghp == "No", planid < 800 or >= 900)
planid_num = pd.to_numeric(plan_data.get("planid"), errors="coerce")

plan_type_year2 = (
    plan_data.loc[
        (plan_data.get("snp") == "No")
        & (plan_data.get("eghp") == "No")
        & ((planid_num < 800) | (planid_num >= 900))
        & _not_na_string(plan_data["plan_type"])
    ]
    .groupby("plan_type", dropna=False)
    .size()
    .reset_index(name="Count")
    .sort_values("Count", ascending=False)
)

# 3) Enrollments by plan type (restricting to plan-fips-year combos in service area)
plan_type_enroll = (
    plan_data.merge(
        service_data[["contractid", "fips", "year"]],
        on=["contractid", "fips", "year"],
        how="inner",
    )
    .loc[
        (lambda d: (d.get("snp") == "No")
                   & (d.get("eghp") == "No")
                   & ((pd.to_numeric(d.get("planid"), errors="coerce") < 800)
                      | (pd.to_numeric(d.get("planid"), errors="coerce") >= 900))
                   & _not_na_string(d["plan_type"]))
    ]
    .groupby("plan_type", dropna=False)
    .agg(
        Count=("plan_type", "size"),
        Avg_Enrollments=("avg_enrollment", "mean"),
    )
    .reset_index()
    .sort_values("Count", ascending=False)
)
```

\newpage
# Building the Data
Answer the following based on our initial, simplified dataset of enrollments, plan types, and service areas:

## 1. Provide a table of plan types in 2015.

```{python}
#| echo: false
#| label: tbl-plans
#| tbl-cap: All plan types in 2015
#| output: asis

# LaTeX table for PDF output
print(plan_type_year1.to_latex(index=False, escape=True))
```

\newpage
\noindent 2. Remove all special needs plans (SNP), employer group plans (eghp), and all "800-series" plans. Provide an updated table after making these exclusions.

I remove the relevant plans just by applying the relevant filters described above. The resulting plan types with these exclusions are presented in @tbl-plans2.

```{python}
#| echo: false
#| label: tbl-plans2
#| tbl-cap: Revised plan types in 2015
#| output: asis

print(plan_type_year2.to_latex(index=False, escape=True))
```

\newpage
\noindent 3. Now calculate the average enrollments by plan type in 2015, using the same exclusions as above.

To do this, I collapse the data to the plan-type level and compute (i) the number of planâ€“county observations and (ii) the mean `avg_enrollment` across the counties in which each plan type operates. The resulting table is presented in @tbl-enroll.

```{python}
#| echo: false
#| label: tbl-enroll
#| tbl-cap: Enrollments by plan type in 2015
#| output: asis

# Round enrollments to 0 digits for presentation (mirrors digits=0 in the R kable call)
tbl = plan_type_enroll.copy()
if "Avg_Enrollments" in tbl.columns:
    tbl["Avg_Enrollments"] = tbl["Avg_Enrollments"].round(0)

print(tbl.to_latex(index=False, escape=True))
```
